from groq import Groq
import os
from dotenv import load_dotenv

load_dotenv()
print("DEBUG GROQ_API_KEY =", os.getenv("GROQ_API_KEY"))

class LLM:
    def __init__(self):
        self.client = Groq(api_key=os.getenv("GROQ_API_KEY"))

        # ==========================================================
        # MASTER SYSTEM PROMPT (CORE INTELLIGENCE LAYER)
        # This defines HOW the AI behaves for ALL PDFs & questions
        # ==========================================================
        self.system_prompt = """
You are an intelligent academic assistant and programming helper.

GENERAL BEHAVIOR RULES (MANDATORY):
- Answer the user's question directly.
- Do NOT ask follow-up questions unless explicitly requested.
- Do NOT offer choices like "Would you like me to...".
- Do NOT repeat the same content multiple times.
- Stop once the answer is complete.

DOCUMENT AWARENESS:
- If a PDF is a QUESTION PAPER:
  • Understand questions come from the paper
  • Answers may NOT exist in the document
  • Use standard, correct academic knowledge to answer
  • Match exam-appropriate depth (not too short, not excessive)

- If a PDF is NOTES / BOOK / REPORT:
  • Use the document content as the primary source
  • Summarize, explain, or extract as asked
  • Do NOT invent topics not present unless clearly required

ANSWERING RULES:
- For factual questions → give precise answers
- For "how many / list / identify" → give exact results
- For explanations → structured, clear, exam-safe language
- Never hallucinate sections, parts, or structure

CODING RULES (VERY IMPORTANT):
- If the user asks for code:
  • Ask NOTHING
  • Just write correct, complete code
- Detect the programming language from the question
- If language is not specified:
  • Use a common academic default (C/C++ for DS, Python for general)
- Ensure:
  • Syntax correctness
  • Logical correctness
  • No deprecated practices
- Do NOT mix languages
- Do NOT explain unless asked

OUTPUT CONTROL:
- Be concise but complete
- Avoid unnecessary verbosity
- Never loop or repeat content
- Never dump entire documents unless explicitly asked

TONE:
- Calm
- Confident
- Teacher-like
- Exam-safe
"""

    def generate(self, prompt: str) -> str:
        """
        Generates a response using Groq LLM.

        This method applies a strong SYSTEM PROMPT to ensure:
        - Correct academic answers
        - Proper handling of question papers vs notes
        - Accurate code generation
        - No infinite or repetitive responses
        """

        response = self.client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=[
                {
                    "role": "system",
                    "content": self.system_prompt
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.3  # Low temperature for precision & exam safety
        )

        return response.choices[0].message.content.strip()

ğŸ“š AI Knowledge Assistant

An AI-powered backend system that allows users to upload documents (PDF/TXT) and ask intelligent, context-aware questions about their content.
This project combines FastAPI, LLMs (Groq), OCR fallback, and vector-based retrieval to handle both text-based and scanned documents reliably.
Built to behave like an academic assistant â€” not a generic chatbot.

ğŸš€ What This Project Does

â€¢Upload PDFs or TXT files
â€¢Automatically extract text
â€¢Uses standard PDF parsing
â€¢Falls back to OCR for scanned PDFs
â€¢Splits content into semantic chunks
â€¢Stores embeddings in a vector store
â€¢Answers questions using LLM + document context

Handles:

â€¢Question papers
â€¢Notes
â€¢Books
â€¢Reports

ğŸ§  Key Features

âœ… Smart Text Extraction
â€¢Text-based PDFs â†’ parsed normally
â€¢Scanned PDFs â†’ OCR fallback (Tesseract + pdf2image)
â€¢Automatic detection of low-text PDFs

âœ… Academic-Aware Answering
Distinguishes between:
â€¢Question papers (answers may not exist in PDF)
â€¢Notes/books (answers must come from document)
â€¢Exam-safe, structured responses
â€¢No hallucinated sections

âœ… Code-Safe LLM Output
â€¢Generates correct, complete code when asked
â€¢Detects programming language automatically
â€¢No unnecessary explanations unless requested

âœ… Backend-First Design
â€¢Clean FastAPI architecture
â€¢Easy to integrate with any frontend (Streamlit / React / etc.)

ğŸ› ï¸ Tech Stack
â€¢Backend: FastAPI
â€¢LLM: Groq (LLaMA 3.1)
â€¢OCR: Tesseract + pdf2image
â€¢PDF Parsing: pypdf
â€¢Embeddings: Vector store (local)
â€¢Environment Management: python-dotenv

ğŸ“¦ Project Structure
ai-knowledge-assistant/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ upload.py
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ file_parser.py
â”‚       â”œâ”€â”€ embeddings.py
â”‚       â”œâ”€â”€ vector_store.py
â”‚       â””â”€â”€ llm.py
â”‚
â”œâ”€â”€ streamlit_app/        
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

âš™ï¸ Local Setup (Recommended Way)
1ï¸âƒ£ Clone the Repository
git clone https://github.com/Manas-Sharma-210/ai-knowledge-assistant.git
cd ai-knowledge-assistant

2ï¸âƒ£ Create Virtual Environment
python -m venv venv

Activate it:

Windows (PowerShell / CMD)
venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Set Environment Variables
Create a .env file in the project root:

GROQ_API_KEY=your_groq_api_key_here

5ï¸âƒ£ (Optional) OCR Setup (Windows)
If you want OCR support for scanned PDFs:
â€¢Install Tesseract OCR
â€¢Install Poppler
â€¢Update the Poppler path inside file_parser.py if needed
â€¢OCR is automatically used only when required.

6ï¸âƒ£ Run the Backend
uvicorn app.main:app --reload

Backend will be live at:
http://127.0.0.1:8000

ğŸ“¡ API Endpoints (Overview)
â€¢POST /upload â†’ Upload document
â€¢POST /answer â†’ Ask questions
â€¢POST /reset â†’ Clear session data
(Designed to be frontend-agnostic)

ğŸ§ª Example Use Cases
-Ask questions from university notes
-Solve questions from scanned question papers
-Extract academic details from PDFs
-Use as backend for:
 â€¢Streamlit app
 â€¢React frontend
 â€¢College projects

 ğŸ§­ Current Status

âœ… Fully working locally
âŒ Cloud deployment deferred (OCR + system dependencies)
ğŸ“Œ Designed to be deployment-ready with containerization later

ğŸ‘¤ Author
Manas Sharma

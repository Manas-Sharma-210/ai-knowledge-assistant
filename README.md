# ğŸ“š AI Knowledge Assistant

An AI-powered backend system that allows users to **upload documents (PDF/TXT)** and ask **intelligent, context-aware questions** about their content.

This project combines **FastAPI**, **LLMs (Groq)**, **OCR fallback**, and **vector-based retrieval** to handle both **text-based and scanned documents** reliably.

> Built to behave like an *academic assistant* â€” not a generic chatbot.

---

## ğŸš€ What This Project Does

* Upload **PDFs or TXT files**
* Automatically extract text

  * Uses standard PDF parsing
  * Falls back to **OCR** for scanned PDFs
* Splits content into semantic chunks
* Stores embeddings in a vector store
* Answers questions using **LLM + document context**
* Handles:

  * Question papers
  * Notes
  * Books
  * Reports

---

## ğŸ§  Key Features

### âœ… Smart Text Extraction

* Text-based PDFs â†’ parsed normally
* Scanned PDFs â†’ OCR fallback (Tesseract + pdf2image)
* Automatic detection of low-text PDFs

### âœ… Academic-Aware Answering

* Distinguishes between:

  * Question papers (answers may not exist in PDF)
  * Notes/books (answers must come from document)
* Exam-safe, structured responses
* No hallucinated sections

### âœ… Code-Safe LLM Output

* Generates **correct, complete code** when asked
* Detects programming language automatically
* No unnecessary explanations unless requested

### âœ… Backend-First Design

* Clean FastAPI architecture
* Easy to integrate with any frontend (Streamlit / React / etc.)

---

## ğŸ› ï¸ Tech Stack

* **Backend**: FastAPI
* **LLM**: Groq (LLaMA 3.1)
* **OCR**: Tesseract + pdf2image
* **PDF Parsing**: pypdf
* **Embeddings**: Vector store (local)
* **Environment Management**: python-dotenv

---

## ğŸ“¦ Project Structure

```
ai-knowledge-assistant/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ upload.py
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ file_parser.py
â”‚       â”œâ”€â”€ embeddings.py
â”‚       â”œâ”€â”€ vector_store.py
â”‚       â””â”€â”€ llm.py
â”‚
â”œâ”€â”€ streamlit_app/        
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âš™ï¸ Local Setup (Recommended Way)

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/Manas-Sharma-210/ai-knowledge-assistant.git
cd ai-knowledge-assistant
```

---

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
```

Activate it:

**Windows (PowerShell / CMD)**

```bash
venv\Scripts\activate
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Set Environment Variables

Create a `.env` file in the project root:

```env
GROQ_API_KEY=your_groq_api_key_here
```



### 5ï¸âƒ£ (Optional) OCR Setup (Windows)

If you want OCR support for scanned PDFs:

* Install **Tesseract OCR**
* Install **Poppler**
* Update the Poppler path inside `file_parser.py` if needed

OCR is automatically used **only when required**.

---

### 6ï¸âƒ£ Run the Backend

```bash
uvicorn app.main:app --reload
```

Backend will be live at:

```
http://127.0.0.1:8000
```

---

## ğŸ“¡ API Endpoints (Overview)

* `POST /upload` â†’ Upload document
* `POST /answer` â†’ Ask questions
* `POST /reset` â†’ Clear session data

(Designed to be frontend-agnostic)

---

## ğŸ§ª Example Use Cases

* Ask questions from university notes
* Solve questions from scanned question papers
* Extract academic details from PDFs
* Use as backend for:

  * Streamlit app
  * React frontend
  * College projects

---

## ğŸ§­ Current Status

* âœ… Fully working locally
* âŒ Cloud deployment deferred (OCR + system dependencies)
* ğŸ“Œ Designed to be deployment-ready with containerization later

---

## ğŸ‘¤ Author

**Manas Sharma**


